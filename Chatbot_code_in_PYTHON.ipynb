{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"Nn89PqrWTjed"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"W2hGju9aGrjs"},"source":["# New Section"]},{"cell_type":"markdown","metadata":{"id":"9Zj9h92wUDPN"},"source":["**Importing the required libraries**"]},{"cell_type":"code","execution_count":12,"metadata":{"executionInfo":{"elapsed":1527,"status":"ok","timestamp":1644387186411,"user":{"displayName":"Sunny Sree3","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gia05Oy0Xl4X6Mza6pH4ZdBAgShZDLEC_LyhOM4qA=s64","userId":"10510659426327499284"},"user_tz":-330},"id":"4BmyocFbb0MJ"},"outputs":[],"source":["import numpy as np\n","import nltk\n","import string\n","import random"]},{"cell_type":"markdown","metadata":{"id":"85QE5FDSUKqU"},"source":["**Importing and reading the corpus**"]},{"cell_type":"code","execution_count":13,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1557,"status":"ok","timestamp":1644387242592,"user":{"displayName":"Sunny Sree3","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gia05Oy0Xl4X6Mza6pH4ZdBAgShZDLEC_LyhOM4qA=s64","userId":"10510659426327499284"},"user_tz":-330},"id":"jouIkYEkb9Pk","outputId":"647db158-fda3-4ef1-e99d-d8abdb7cd13b"},"outputs":[{"name":"stderr","output_type":"stream","text":["[nltk_data] Error loading punkt: <urlopen error [Errno 11001]\n","[nltk_data]     getaddrinfo failed>\n","[nltk_data] Error loading wordnet: <urlopen error [Errno 11001]\n","[nltk_data]     getaddrinfo failed>\n"]}],"source":["f=open('chatbot.txt','r',errors = 'ignore')\n","raw_doc=f.read()\n","raw_doc=raw_doc.lower() #Converts text to lowercase\n","nltk.download('punkt') #Using the Punkt tokenizer\n","nltk.download('wordnet') #Using the WordNet dictionary\n","sent_tokens = nltk.sent_tokenize(raw_doc) #Converts doc to list of sentences \n","word_tokens = nltk.word_tokenize(raw_doc) #Converts doc to list of words"]},{"cell_type":"markdown","metadata":{"id":"pmXgGkVeUSUb"},"source":["**Example of sentance tokens**"]},{"cell_type":"code","execution_count":14,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":406,"status":"ok","timestamp":1644387246131,"user":{"displayName":"Sunny Sree3","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gia05Oy0Xl4X6Mza6pH4ZdBAgShZDLEC_LyhOM4qA=s64","userId":"10510659426327499284"},"user_tz":-330},"id":"Swu4WRVncPR8","outputId":"8b1b89e8-9283-44e3-c333-826939392adb"},"outputs":[{"data":{"text/plain":["['data science\\nfrom wikipedia, the free encyclopedia\\njump to navigationjump to search\\nnot to be confused with information science.',\n"," 'the existence of comet neowise (here depicted as a series of red dots) was discovered by analyzing astronomical survey data acquired by a space telescope, the wide-field infrared survey explorer.']"]},"execution_count":14,"metadata":{},"output_type":"execute_result"}],"source":["sent_tokens[:2]"]},{"cell_type":"markdown","metadata":{"id":"Gtkzd0KhUWJT"},"source":["**Example of word tokens**"]},{"cell_type":"code","execution_count":15,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":405,"status":"ok","timestamp":1644387249974,"user":{"displayName":"Sunny Sree3","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gia05Oy0Xl4X6Mza6pH4ZdBAgShZDLEC_LyhOM4qA=s64","userId":"10510659426327499284"},"user_tz":-330},"id":"hcwrvmWicaLc","outputId":"31a9615d-fb0a-4a08-fdeb-57c5802f06e6"},"outputs":[{"data":{"text/plain":["['data', 'science']"]},"execution_count":15,"metadata":{},"output_type":"execute_result"}],"source":["word_tokens[:2]"]},{"cell_type":"markdown","metadata":{"id":"bvvYcZZ9UbVD"},"source":["**Text preprocessing**"]},{"cell_type":"code","execution_count":16,"metadata":{"executionInfo":{"elapsed":703,"status":"ok","timestamp":1644387252621,"user":{"displayName":"Sunny Sree3","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gia05Oy0Xl4X6Mza6pH4ZdBAgShZDLEC_LyhOM4qA=s64","userId":"10510659426327499284"},"user_tz":-330},"id":"YbZllVqBcc78"},"outputs":[],"source":["lemmer = nltk.stem.WordNetLemmatizer()\n","#WordNet is a semantically-oriented dictionary of English included in NLTK.\n","def LemTokens(tokens):\n","    return [lemmer.lemmatize(token) for token in tokens]\n","remove_punct_dict = dict((ord(punct), None) for punct in string.punctuation)\n","def LemNormalize(text):\n","    return LemTokens(nltk.word_tokenize(text.lower().translate(remove_punct_dict)))"]},{"cell_type":"markdown","metadata":{"id":"tLX8WBE4UgOr"},"source":["**Defining the greeting function**"]},{"cell_type":"code","execution_count":17,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1644387254415,"user":{"displayName":"Sunny Sree3","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gia05Oy0Xl4X6Mza6pH4ZdBAgShZDLEC_LyhOM4qA=s64","userId":"10510659426327499284"},"user_tz":-330},"id":"dLOqphibchJM"},"outputs":[],"source":["GREET_INPUTS = (\"hello\", \"hi\", \"greetings\", \"sup\", \"what's up\",\"hey\")\n","GREET_RESPONSES = [\"hi\", \"hey\", \"*nods*\", \"hi there\", \"hello\", \"I am glad! You are talking to me\"]\n","def greet(sentence):\n"," \n","    for word in sentence.split():\n","        if word.lower() in GREET_INPUTS:\n","            return random.choice(GREET_RESPONSES)"]},{"cell_type":"markdown","metadata":{"id":"qJhFmyRCUm4j"},"source":["**Response generation**"]},{"cell_type":"code","execution_count":18,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1644387256272,"user":{"displayName":"Sunny Sree3","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gia05Oy0Xl4X6Mza6pH4ZdBAgShZDLEC_LyhOM4qA=s64","userId":"10510659426327499284"},"user_tz":-330},"id":"eo7Kv52HcjG0"},"outputs":[],"source":["from sklearn.feature_extraction.text import TfidfVectorizer\n","from sklearn.metrics.pairwise import cosine_similarity"]},{"cell_type":"code","execution_count":19,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1644387258184,"user":{"displayName":"Sunny Sree3","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gia05Oy0Xl4X6Mza6pH4ZdBAgShZDLEC_LyhOM4qA=s64","userId":"10510659426327499284"},"user_tz":-330},"id":"JEHZesw3cnNM"},"outputs":[],"source":["def response(user_response):\n","  robo1_response=''\n","  TfidfVec = TfidfVectorizer(tokenizer=LemNormalize, stop_words='english')\n","  tfidf = TfidfVec.fit_transform(sent_tokens)\n","  vals = cosine_similarity(tfidf[-1], tfidf)\n","  idx=vals.argsort()[0][-2]\n","  flat = vals.flatten()\n","  flat.sort()\n","  req_tfidf = flat[-2]\n","  if(req_tfidf==0):\n","    robo1_response=robo1_response+\"I am sorry! I don't understand you\"\n","    return robo1_response\n","  else:\n","    robo1_response = robo1_response+sent_tokens[idx]\n","    return robo1_response"]},{"cell_type":"markdown","metadata":{"id":"1Q-iY_o1Utas"},"source":["**Defining conversation start/end protocols**"]},{"cell_type":"code","execution_count":20,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":94212,"status":"ok","timestamp":1644387354576,"user":{"displayName":"Sunny Sree3","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gia05Oy0Xl4X6Mza6pH4ZdBAgShZDLEC_LyhOM4qA=s64","userId":"10510659426327499284"},"user_tz":-330},"id":"wxzENVDgdNGd","outputId":"73950c19-a1dd-4180-a404-14a4b2956dd5"},"outputs":[{"name":"stdout","output_type":"stream","text":["BOT: My name is Stark. Let's have a conversation! Also, if you want to exit any time, just type Bye!\n","BOT: I am glad! You are talking to me\n","BOT: "]},{"ename":"LookupError","evalue":"\n**********************************************************************\n  Resource \u001b[93momw-1.4\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('omw-1.4')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mcorpora/omw-1.4\u001b[0m\n\n  Searched in:\n    - 'C:\\\\Users\\\\BHAVYA SREE/nltk_data'\n    - 'C:\\\\Users\\\\BHAVYA SREE\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python39\\\\nltk_data'\n    - 'C:\\\\Users\\\\BHAVYA SREE\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python39\\\\share\\\\nltk_data'\n    - 'C:\\\\Users\\\\BHAVYA SREE\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python39\\\\lib\\\\nltk_data'\n    - 'C:\\\\Users\\\\BHAVYA SREE\\\\AppData\\\\Roaming\\\\nltk_data'\n    - 'C:\\\\nltk_data'\n    - 'D:\\\\nltk_data'\n    - 'E:\\\\nltk_data'\n**********************************************************************\n","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mLookupError\u001b[0m                               Traceback (most recent call last)","File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\nltk\\corpus\\util.py:84\u001b[0m, in \u001b[0;36mLazyCorpusLoader.__load\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     <a href='file:///~/AppData/Local/Programs/Python/Python39/lib/site-packages/nltk/corpus/util.py?line=82'>83</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> <a href='file:///~/AppData/Local/Programs/Python/Python39/lib/site-packages/nltk/corpus/util.py?line=83'>84</a>\u001b[0m     root \u001b[39m=\u001b[39m nltk\u001b[39m.\u001b[39;49mdata\u001b[39m.\u001b[39;49mfind(\u001b[39mf\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m{\u001b[39;49;00m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msubdir\u001b[39m}\u001b[39;49;00m\u001b[39m/\u001b[39;49m\u001b[39m{\u001b[39;49;00mzip_name\u001b[39m}\u001b[39;49;00m\u001b[39m\"\u001b[39;49m)\n\u001b[0;32m     <a href='file:///~/AppData/Local/Programs/Python/Python39/lib/site-packages/nltk/corpus/util.py?line=84'>85</a>\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mLookupError\u001b[39;00m:\n","File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\nltk\\data.py:583\u001b[0m, in \u001b[0;36mfind\u001b[1;34m(resource_name, paths)\u001b[0m\n\u001b[0;32m    <a href='file:///~/AppData/Local/Programs/Python/Python39/lib/site-packages/nltk/data.py?line=581'>582</a>\u001b[0m resource_not_found \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00msep\u001b[39m}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00mmsg\u001b[39m}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00msep\u001b[39m}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m--> <a href='file:///~/AppData/Local/Programs/Python/Python39/lib/site-packages/nltk/data.py?line=582'>583</a>\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mLookupError\u001b[39;00m(resource_not_found)\n","\u001b[1;31mLookupError\u001b[0m: \n**********************************************************************\n  Resource \u001b[93momw-1.4\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('omw-1.4')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mcorpora/omw-1.4.zip/omw-1.4/\u001b[0m\n\n  Searched in:\n    - 'C:\\\\Users\\\\BHAVYA SREE/nltk_data'\n    - 'C:\\\\Users\\\\BHAVYA SREE\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python39\\\\nltk_data'\n    - 'C:\\\\Users\\\\BHAVYA SREE\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python39\\\\share\\\\nltk_data'\n    - 'C:\\\\Users\\\\BHAVYA SREE\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python39\\\\lib\\\\nltk_data'\n    - 'C:\\\\Users\\\\BHAVYA SREE\\\\AppData\\\\Roaming\\\\nltk_data'\n    - 'C:\\\\nltk_data'\n    - 'D:\\\\nltk_data'\n    - 'E:\\\\nltk_data'\n**********************************************************************\n","\nDuring handling of the above exception, another exception occurred:\n","\u001b[1;31mLookupError\u001b[0m                               Traceback (most recent call last)","\u001b[1;32mc:\\Users\\BHAVYA SREE\\OneDrive\\Desktop\\Bhavya\\Chatbot-in-Python\\Chatbot_code_in_PYTHON.ipynb Cell 19'\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/BHAVYA%20SREE/OneDrive/Desktop/Bhavya/Chatbot-in-Python/Chatbot_code_in_PYTHON.ipynb#ch0000018?line=15'>16</a>\u001b[0m             final_words\u001b[39m=\u001b[39m\u001b[39mlist\u001b[39m(\u001b[39mset\u001b[39m(word_tokens))\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/BHAVYA%20SREE/OneDrive/Desktop/Bhavya/Chatbot-in-Python/Chatbot_code_in_PYTHON.ipynb#ch0000018?line=16'>17</a>\u001b[0m             \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mBOT: \u001b[39m\u001b[39m\"\u001b[39m,end\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/BHAVYA%20SREE/OneDrive/Desktop/Bhavya/Chatbot-in-Python/Chatbot_code_in_PYTHON.ipynb#ch0000018?line=17'>18</a>\u001b[0m             \u001b[39mprint\u001b[39m(response(user_response))\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/BHAVYA%20SREE/OneDrive/Desktop/Bhavya/Chatbot-in-Python/Chatbot_code_in_PYTHON.ipynb#ch0000018?line=18'>19</a>\u001b[0m             sent_tokens\u001b[39m.\u001b[39mremove(user_response)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/BHAVYA%20SREE/OneDrive/Desktop/Bhavya/Chatbot-in-Python/Chatbot_code_in_PYTHON.ipynb#ch0000018?line=19'>20</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n","\u001b[1;32mc:\\Users\\BHAVYA SREE\\OneDrive\\Desktop\\Bhavya\\Chatbot-in-Python\\Chatbot_code_in_PYTHON.ipynb Cell 17'\u001b[0m in \u001b[0;36mresponse\u001b[1;34m(user_response)\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/BHAVYA%20SREE/OneDrive/Desktop/Bhavya/Chatbot-in-Python/Chatbot_code_in_PYTHON.ipynb#ch0000016?line=1'>2</a>\u001b[0m robo1_response\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/BHAVYA%20SREE/OneDrive/Desktop/Bhavya/Chatbot-in-Python/Chatbot_code_in_PYTHON.ipynb#ch0000016?line=2'>3</a>\u001b[0m TfidfVec \u001b[39m=\u001b[39m TfidfVectorizer(tokenizer\u001b[39m=\u001b[39mLemNormalize, stop_words\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39menglish\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/BHAVYA%20SREE/OneDrive/Desktop/Bhavya/Chatbot-in-Python/Chatbot_code_in_PYTHON.ipynb#ch0000016?line=3'>4</a>\u001b[0m tfidf \u001b[39m=\u001b[39m TfidfVec\u001b[39m.\u001b[39;49mfit_transform(sent_tokens)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/BHAVYA%20SREE/OneDrive/Desktop/Bhavya/Chatbot-in-Python/Chatbot_code_in_PYTHON.ipynb#ch0000016?line=4'>5</a>\u001b[0m vals \u001b[39m=\u001b[39m cosine_similarity(tfidf[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m], tfidf)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/BHAVYA%20SREE/OneDrive/Desktop/Bhavya/Chatbot-in-Python/Chatbot_code_in_PYTHON.ipynb#ch0000016?line=5'>6</a>\u001b[0m idx\u001b[39m=\u001b[39mvals\u001b[39m.\u001b[39margsort()[\u001b[39m0\u001b[39m][\u001b[39m-\u001b[39m\u001b[39m2\u001b[39m]\n","File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:2077\u001b[0m, in \u001b[0;36mTfidfVectorizer.fit_transform\u001b[1;34m(self, raw_documents, y)\u001b[0m\n\u001b[0;32m   <a href='file:///~/AppData/Local/Programs/Python/Python39/lib/site-packages/sklearn/feature_extraction/text.py?line=2057'>2058</a>\u001b[0m \u001b[39m\"\"\"Learn vocabulary and idf, return document-term matrix.\u001b[39;00m\n\u001b[0;32m   <a href='file:///~/AppData/Local/Programs/Python/Python39/lib/site-packages/sklearn/feature_extraction/text.py?line=2058'>2059</a>\u001b[0m \n\u001b[0;32m   <a href='file:///~/AppData/Local/Programs/Python/Python39/lib/site-packages/sklearn/feature_extraction/text.py?line=2059'>2060</a>\u001b[0m \u001b[39mThis is equivalent to fit followed by transform, but more efficiently\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   <a href='file:///~/AppData/Local/Programs/Python/Python39/lib/site-packages/sklearn/feature_extraction/text.py?line=2073'>2074</a>\u001b[0m \u001b[39m    Tf-idf-weighted document-term matrix.\u001b[39;00m\n\u001b[0;32m   <a href='file:///~/AppData/Local/Programs/Python/Python39/lib/site-packages/sklearn/feature_extraction/text.py?line=2074'>2075</a>\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   <a href='file:///~/AppData/Local/Programs/Python/Python39/lib/site-packages/sklearn/feature_extraction/text.py?line=2075'>2076</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_params()\n\u001b[1;32m-> <a href='file:///~/AppData/Local/Programs/Python/Python39/lib/site-packages/sklearn/feature_extraction/text.py?line=2076'>2077</a>\u001b[0m X \u001b[39m=\u001b[39m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mfit_transform(raw_documents)\n\u001b[0;32m   <a href='file:///~/AppData/Local/Programs/Python/Python39/lib/site-packages/sklearn/feature_extraction/text.py?line=2077'>2078</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_tfidf\u001b[39m.\u001b[39mfit(X)\n\u001b[0;32m   <a href='file:///~/AppData/Local/Programs/Python/Python39/lib/site-packages/sklearn/feature_extraction/text.py?line=2078'>2079</a>\u001b[0m \u001b[39m# X is already a transformed view of raw_documents so\u001b[39;00m\n\u001b[0;32m   <a href='file:///~/AppData/Local/Programs/Python/Python39/lib/site-packages/sklearn/feature_extraction/text.py?line=2079'>2080</a>\u001b[0m \u001b[39m# we set copy to False\u001b[39;00m\n","File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:1330\u001b[0m, in \u001b[0;36mCountVectorizer.fit_transform\u001b[1;34m(self, raw_documents, y)\u001b[0m\n\u001b[0;32m   <a href='file:///~/AppData/Local/Programs/Python/Python39/lib/site-packages/sklearn/feature_extraction/text.py?line=1321'>1322</a>\u001b[0m             warnings\u001b[39m.\u001b[39mwarn(\n\u001b[0;32m   <a href='file:///~/AppData/Local/Programs/Python/Python39/lib/site-packages/sklearn/feature_extraction/text.py?line=1322'>1323</a>\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39mUpper case characters found in\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   <a href='file:///~/AppData/Local/Programs/Python/Python39/lib/site-packages/sklearn/feature_extraction/text.py?line=1323'>1324</a>\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39m vocabulary while \u001b[39m\u001b[39m'\u001b[39m\u001b[39mlowercase\u001b[39m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   <a href='file:///~/AppData/Local/Programs/Python/Python39/lib/site-packages/sklearn/feature_extraction/text.py?line=1324'>1325</a>\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39m is True. These entries will not\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   <a href='file:///~/AppData/Local/Programs/Python/Python39/lib/site-packages/sklearn/feature_extraction/text.py?line=1325'>1326</a>\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39m be matched with any documents\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   <a href='file:///~/AppData/Local/Programs/Python/Python39/lib/site-packages/sklearn/feature_extraction/text.py?line=1326'>1327</a>\u001b[0m             )\n\u001b[0;32m   <a href='file:///~/AppData/Local/Programs/Python/Python39/lib/site-packages/sklearn/feature_extraction/text.py?line=1327'>1328</a>\u001b[0m             \u001b[39mbreak\u001b[39;00m\n\u001b[1;32m-> <a href='file:///~/AppData/Local/Programs/Python/Python39/lib/site-packages/sklearn/feature_extraction/text.py?line=1329'>1330</a>\u001b[0m vocabulary, X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_count_vocab(raw_documents, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfixed_vocabulary_)\n\u001b[0;32m   <a href='file:///~/AppData/Local/Programs/Python/Python39/lib/site-packages/sklearn/feature_extraction/text.py?line=1331'>1332</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbinary:\n\u001b[0;32m   <a href='file:///~/AppData/Local/Programs/Python/Python39/lib/site-packages/sklearn/feature_extraction/text.py?line=1332'>1333</a>\u001b[0m     X\u001b[39m.\u001b[39mdata\u001b[39m.\u001b[39mfill(\u001b[39m1\u001b[39m)\n","File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:1201\u001b[0m, in \u001b[0;36mCountVectorizer._count_vocab\u001b[1;34m(self, raw_documents, fixed_vocab)\u001b[0m\n\u001b[0;32m   <a href='file:///~/AppData/Local/Programs/Python/Python39/lib/site-packages/sklearn/feature_extraction/text.py?line=1198'>1199</a>\u001b[0m \u001b[39mfor\u001b[39;00m doc \u001b[39min\u001b[39;00m raw_documents:\n\u001b[0;32m   <a href='file:///~/AppData/Local/Programs/Python/Python39/lib/site-packages/sklearn/feature_extraction/text.py?line=1199'>1200</a>\u001b[0m     feature_counter \u001b[39m=\u001b[39m {}\n\u001b[1;32m-> <a href='file:///~/AppData/Local/Programs/Python/Python39/lib/site-packages/sklearn/feature_extraction/text.py?line=1200'>1201</a>\u001b[0m     \u001b[39mfor\u001b[39;00m feature \u001b[39min\u001b[39;00m analyze(doc):\n\u001b[0;32m   <a href='file:///~/AppData/Local/Programs/Python/Python39/lib/site-packages/sklearn/feature_extraction/text.py?line=1201'>1202</a>\u001b[0m         \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m   <a href='file:///~/AppData/Local/Programs/Python/Python39/lib/site-packages/sklearn/feature_extraction/text.py?line=1202'>1203</a>\u001b[0m             feature_idx \u001b[39m=\u001b[39m vocabulary[feature]\n","File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:115\u001b[0m, in \u001b[0;36m_analyze\u001b[1;34m(doc, analyzer, tokenizer, ngrams, preprocessor, decoder, stop_words)\u001b[0m\n\u001b[0;32m    <a href='file:///~/AppData/Local/Programs/Python/Python39/lib/site-packages/sklearn/feature_extraction/text.py?line=112'>113</a>\u001b[0m     doc \u001b[39m=\u001b[39m preprocessor(doc)\n\u001b[0;32m    <a href='file:///~/AppData/Local/Programs/Python/Python39/lib/site-packages/sklearn/feature_extraction/text.py?line=113'>114</a>\u001b[0m \u001b[39mif\u001b[39;00m tokenizer \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> <a href='file:///~/AppData/Local/Programs/Python/Python39/lib/site-packages/sklearn/feature_extraction/text.py?line=114'>115</a>\u001b[0m     doc \u001b[39m=\u001b[39m tokenizer(doc)\n\u001b[0;32m    <a href='file:///~/AppData/Local/Programs/Python/Python39/lib/site-packages/sklearn/feature_extraction/text.py?line=115'>116</a>\u001b[0m \u001b[39mif\u001b[39;00m ngrams \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    <a href='file:///~/AppData/Local/Programs/Python/Python39/lib/site-packages/sklearn/feature_extraction/text.py?line=116'>117</a>\u001b[0m     \u001b[39mif\u001b[39;00m stop_words \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n","\u001b[1;32mc:\\Users\\BHAVYA SREE\\OneDrive\\Desktop\\Bhavya\\Chatbot-in-Python\\Chatbot_code_in_PYTHON.ipynb Cell 12'\u001b[0m in \u001b[0;36mLemNormalize\u001b[1;34m(text)\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/BHAVYA%20SREE/OneDrive/Desktop/Bhavya/Chatbot-in-Python/Chatbot_code_in_PYTHON.ipynb#ch0000011?line=5'>6</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mLemNormalize\u001b[39m(text):\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/BHAVYA%20SREE/OneDrive/Desktop/Bhavya/Chatbot-in-Python/Chatbot_code_in_PYTHON.ipynb#ch0000011?line=6'>7</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m LemTokens(nltk\u001b[39m.\u001b[39;49mword_tokenize(text\u001b[39m.\u001b[39;49mlower()\u001b[39m.\u001b[39;49mtranslate(remove_punct_dict)))\n","\u001b[1;32mc:\\Users\\BHAVYA SREE\\OneDrive\\Desktop\\Bhavya\\Chatbot-in-Python\\Chatbot_code_in_PYTHON.ipynb Cell 12'\u001b[0m in \u001b[0;36mLemTokens\u001b[1;34m(tokens)\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/BHAVYA%20SREE/OneDrive/Desktop/Bhavya/Chatbot-in-Python/Chatbot_code_in_PYTHON.ipynb#ch0000011?line=2'>3</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mLemTokens\u001b[39m(tokens):\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/BHAVYA%20SREE/OneDrive/Desktop/Bhavya/Chatbot-in-Python/Chatbot_code_in_PYTHON.ipynb#ch0000011?line=3'>4</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m [lemmer\u001b[39m.\u001b[39mlemmatize(token) \u001b[39mfor\u001b[39;00m token \u001b[39min\u001b[39;00m tokens]\n","\u001b[1;32mc:\\Users\\BHAVYA SREE\\OneDrive\\Desktop\\Bhavya\\Chatbot-in-Python\\Chatbot_code_in_PYTHON.ipynb Cell 12'\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/BHAVYA%20SREE/OneDrive/Desktop/Bhavya/Chatbot-in-Python/Chatbot_code_in_PYTHON.ipynb#ch0000011?line=2'>3</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mLemTokens\u001b[39m(tokens):\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/BHAVYA%20SREE/OneDrive/Desktop/Bhavya/Chatbot-in-Python/Chatbot_code_in_PYTHON.ipynb#ch0000011?line=3'>4</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m [lemmer\u001b[39m.\u001b[39;49mlemmatize(token) \u001b[39mfor\u001b[39;00m token \u001b[39min\u001b[39;00m tokens]\n","File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\nltk\\stem\\wordnet.py:45\u001b[0m, in \u001b[0;36mWordNetLemmatizer.lemmatize\u001b[1;34m(self, word, pos)\u001b[0m\n\u001b[0;32m     <a href='file:///~/AppData/Local/Programs/Python/Python39/lib/site-packages/nltk/stem/wordnet.py?line=32'>33</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mlemmatize\u001b[39m(\u001b[39mself\u001b[39m, word: \u001b[39mstr\u001b[39m, pos: \u001b[39mstr\u001b[39m \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mn\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mstr\u001b[39m:\n\u001b[0;32m     <a href='file:///~/AppData/Local/Programs/Python/Python39/lib/site-packages/nltk/stem/wordnet.py?line=33'>34</a>\u001b[0m     \u001b[39m\"\"\"Lemmatize `word` using WordNet's built-in morphy function.\u001b[39;00m\n\u001b[0;32m     <a href='file:///~/AppData/Local/Programs/Python/Python39/lib/site-packages/nltk/stem/wordnet.py?line=34'>35</a>\u001b[0m \u001b[39m    Returns the input word unchanged if it cannot be found in WordNet.\u001b[39;00m\n\u001b[0;32m     <a href='file:///~/AppData/Local/Programs/Python/Python39/lib/site-packages/nltk/stem/wordnet.py?line=35'>36</a>\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     <a href='file:///~/AppData/Local/Programs/Python/Python39/lib/site-packages/nltk/stem/wordnet.py?line=42'>43</a>\u001b[0m \u001b[39m    :return: The lemma of `word`, for the given `pos`.\u001b[39;00m\n\u001b[0;32m     <a href='file:///~/AppData/Local/Programs/Python/Python39/lib/site-packages/nltk/stem/wordnet.py?line=43'>44</a>\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> <a href='file:///~/AppData/Local/Programs/Python/Python39/lib/site-packages/nltk/stem/wordnet.py?line=44'>45</a>\u001b[0m     lemmas \u001b[39m=\u001b[39m wn\u001b[39m.\u001b[39;49m_morphy(word, pos)\n\u001b[0;32m     <a href='file:///~/AppData/Local/Programs/Python/Python39/lib/site-packages/nltk/stem/wordnet.py?line=45'>46</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mmin\u001b[39m(lemmas, key\u001b[39m=\u001b[39m\u001b[39mlen\u001b[39m) \u001b[39mif\u001b[39;00m lemmas \u001b[39melse\u001b[39;00m word\n","File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\nltk\\corpus\\util.py:121\u001b[0m, in \u001b[0;36mLazyCorpusLoader.__getattr__\u001b[1;34m(self, attr)\u001b[0m\n\u001b[0;32m    <a href='file:///~/AppData/Local/Programs/Python/Python39/lib/site-packages/nltk/corpus/util.py?line=117'>118</a>\u001b[0m \u001b[39mif\u001b[39;00m attr \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m__bases__\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m    <a href='file:///~/AppData/Local/Programs/Python/Python39/lib/site-packages/nltk/corpus/util.py?line=118'>119</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mAttributeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mLazyCorpusLoader object has no attribute \u001b[39m\u001b[39m'\u001b[39m\u001b[39m__bases__\u001b[39m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m--> <a href='file:///~/AppData/Local/Programs/Python/Python39/lib/site-packages/nltk/corpus/util.py?line=120'>121</a>\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m__load()\n\u001b[0;32m    <a href='file:///~/AppData/Local/Programs/Python/Python39/lib/site-packages/nltk/corpus/util.py?line=121'>122</a>\u001b[0m \u001b[39m# This looks circular, but its not, since __load() changes our\u001b[39;00m\n\u001b[0;32m    <a href='file:///~/AppData/Local/Programs/Python/Python39/lib/site-packages/nltk/corpus/util.py?line=122'>123</a>\u001b[0m \u001b[39m# __class__ to something new:\u001b[39;00m\n\u001b[0;32m    <a href='file:///~/AppData/Local/Programs/Python/Python39/lib/site-packages/nltk/corpus/util.py?line=123'>124</a>\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39m, attr)\n","File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\nltk\\corpus\\util.py:89\u001b[0m, in \u001b[0;36mLazyCorpusLoader.__load\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     <a href='file:///~/AppData/Local/Programs/Python/Python39/lib/site-packages/nltk/corpus/util.py?line=85'>86</a>\u001b[0m             \u001b[39mraise\u001b[39;00m e\n\u001b[0;32m     <a href='file:///~/AppData/Local/Programs/Python/Python39/lib/site-packages/nltk/corpus/util.py?line=87'>88</a>\u001b[0m \u001b[39m# Load the corpus.\u001b[39;00m\n\u001b[1;32m---> <a href='file:///~/AppData/Local/Programs/Python/Python39/lib/site-packages/nltk/corpus/util.py?line=88'>89</a>\u001b[0m corpus \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__reader_cls(root, \u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__args, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__kwargs)\n\u001b[0;32m     <a href='file:///~/AppData/Local/Programs/Python/Python39/lib/site-packages/nltk/corpus/util.py?line=90'>91</a>\u001b[0m \u001b[39m# This is where the magic happens!  Transform ourselves into\u001b[39;00m\n\u001b[0;32m     <a href='file:///~/AppData/Local/Programs/Python/Python39/lib/site-packages/nltk/corpus/util.py?line=91'>92</a>\u001b[0m \u001b[39m# the corpus by modifying our own __dict__ and __class__ to\u001b[39;00m\n\u001b[0;32m     <a href='file:///~/AppData/Local/Programs/Python/Python39/lib/site-packages/nltk/corpus/util.py?line=92'>93</a>\u001b[0m \u001b[39m# match that of the corpus.\u001b[39;00m\n\u001b[0;32m     <a href='file:///~/AppData/Local/Programs/Python/Python39/lib/site-packages/nltk/corpus/util.py?line=94'>95</a>\u001b[0m args, kwargs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__args, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__kwargs\n","File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\nltk\\corpus\\reader\\wordnet.py:1176\u001b[0m, in \u001b[0;36mWordNetCorpusReader.__init__\u001b[1;34m(self, root, omw_reader)\u001b[0m\n\u001b[0;32m   <a href='file:///~/AppData/Local/Programs/Python/Python39/lib/site-packages/nltk/corpus/reader/wordnet.py?line=1171'>1172</a>\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[0;32m   <a href='file:///~/AppData/Local/Programs/Python/Python39/lib/site-packages/nltk/corpus/reader/wordnet.py?line=1172'>1173</a>\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mThe multilingual functions are not available with this Wordnet version\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   <a href='file:///~/AppData/Local/Programs/Python/Python39/lib/site-packages/nltk/corpus/reader/wordnet.py?line=1173'>1174</a>\u001b[0m     )\n\u001b[0;32m   <a href='file:///~/AppData/Local/Programs/Python/Python39/lib/site-packages/nltk/corpus/reader/wordnet.py?line=1174'>1175</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> <a href='file:///~/AppData/Local/Programs/Python/Python39/lib/site-packages/nltk/corpus/reader/wordnet.py?line=1175'>1176</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprovenances \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49momw_prov()\n\u001b[0;32m   <a href='file:///~/AppData/Local/Programs/Python/Python39/lib/site-packages/nltk/corpus/reader/wordnet.py?line=1177'>1178</a>\u001b[0m \u001b[39m# A cache to store the wordnet data of multiple languages\u001b[39;00m\n\u001b[0;32m   <a href='file:///~/AppData/Local/Programs/Python/Python39/lib/site-packages/nltk/corpus/reader/wordnet.py?line=1178'>1179</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lang_data \u001b[39m=\u001b[39m defaultdict(\u001b[39mlist\u001b[39m)\n","File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\nltk\\corpus\\reader\\wordnet.py:1285\u001b[0m, in \u001b[0;36mWordNetCorpusReader.omw_prov\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   <a href='file:///~/AppData/Local/Programs/Python/Python39/lib/site-packages/nltk/corpus/reader/wordnet.py?line=1282'>1283</a>\u001b[0m provdict \u001b[39m=\u001b[39m {}\n\u001b[0;32m   <a href='file:///~/AppData/Local/Programs/Python/Python39/lib/site-packages/nltk/corpus/reader/wordnet.py?line=1283'>1284</a>\u001b[0m provdict[\u001b[39m\"\u001b[39m\u001b[39meng\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m-> <a href='file:///~/AppData/Local/Programs/Python/Python39/lib/site-packages/nltk/corpus/reader/wordnet.py?line=1284'>1285</a>\u001b[0m fileids \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_omw_reader\u001b[39m.\u001b[39;49mfileids()\n\u001b[0;32m   <a href='file:///~/AppData/Local/Programs/Python/Python39/lib/site-packages/nltk/corpus/reader/wordnet.py?line=1285'>1286</a>\u001b[0m \u001b[39mfor\u001b[39;00m fileid \u001b[39min\u001b[39;00m fileids:\n\u001b[0;32m   <a href='file:///~/AppData/Local/Programs/Python/Python39/lib/site-packages/nltk/corpus/reader/wordnet.py?line=1286'>1287</a>\u001b[0m     prov, langfile \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39msplit(fileid)\n","File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\nltk\\corpus\\util.py:121\u001b[0m, in \u001b[0;36mLazyCorpusLoader.__getattr__\u001b[1;34m(self, attr)\u001b[0m\n\u001b[0;32m    <a href='file:///~/AppData/Local/Programs/Python/Python39/lib/site-packages/nltk/corpus/util.py?line=117'>118</a>\u001b[0m \u001b[39mif\u001b[39;00m attr \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m__bases__\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m    <a href='file:///~/AppData/Local/Programs/Python/Python39/lib/site-packages/nltk/corpus/util.py?line=118'>119</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mAttributeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mLazyCorpusLoader object has no attribute \u001b[39m\u001b[39m'\u001b[39m\u001b[39m__bases__\u001b[39m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m--> <a href='file:///~/AppData/Local/Programs/Python/Python39/lib/site-packages/nltk/corpus/util.py?line=120'>121</a>\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m__load()\n\u001b[0;32m    <a href='file:///~/AppData/Local/Programs/Python/Python39/lib/site-packages/nltk/corpus/util.py?line=121'>122</a>\u001b[0m \u001b[39m# This looks circular, but its not, since __load() changes our\u001b[39;00m\n\u001b[0;32m    <a href='file:///~/AppData/Local/Programs/Python/Python39/lib/site-packages/nltk/corpus/util.py?line=122'>123</a>\u001b[0m \u001b[39m# __class__ to something new:\u001b[39;00m\n\u001b[0;32m    <a href='file:///~/AppData/Local/Programs/Python/Python39/lib/site-packages/nltk/corpus/util.py?line=123'>124</a>\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39m, attr)\n","File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\nltk\\corpus\\util.py:86\u001b[0m, in \u001b[0;36mLazyCorpusLoader.__load\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     <a href='file:///~/AppData/Local/Programs/Python/Python39/lib/site-packages/nltk/corpus/util.py?line=83'>84</a>\u001b[0m             root \u001b[39m=\u001b[39m nltk\u001b[39m.\u001b[39mdata\u001b[39m.\u001b[39mfind(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msubdir\u001b[39m}\u001b[39;00m\u001b[39m/\u001b[39m\u001b[39m{\u001b[39;00mzip_name\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     <a href='file:///~/AppData/Local/Programs/Python/Python39/lib/site-packages/nltk/corpus/util.py?line=84'>85</a>\u001b[0m         \u001b[39mexcept\u001b[39;00m \u001b[39mLookupError\u001b[39;00m:\n\u001b[1;32m---> <a href='file:///~/AppData/Local/Programs/Python/Python39/lib/site-packages/nltk/corpus/util.py?line=85'>86</a>\u001b[0m             \u001b[39mraise\u001b[39;00m e\n\u001b[0;32m     <a href='file:///~/AppData/Local/Programs/Python/Python39/lib/site-packages/nltk/corpus/util.py?line=87'>88</a>\u001b[0m \u001b[39m# Load the corpus.\u001b[39;00m\n\u001b[0;32m     <a href='file:///~/AppData/Local/Programs/Python/Python39/lib/site-packages/nltk/corpus/util.py?line=88'>89</a>\u001b[0m corpus \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__reader_cls(root, \u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__args, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__kwargs)\n","File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\nltk\\corpus\\util.py:81\u001b[0m, in \u001b[0;36mLazyCorpusLoader.__load\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     <a href='file:///~/AppData/Local/Programs/Python/Python39/lib/site-packages/nltk/corpus/util.py?line=78'>79</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     <a href='file:///~/AppData/Local/Programs/Python/Python39/lib/site-packages/nltk/corpus/util.py?line=79'>80</a>\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> <a href='file:///~/AppData/Local/Programs/Python/Python39/lib/site-packages/nltk/corpus/util.py?line=80'>81</a>\u001b[0m         root \u001b[39m=\u001b[39m nltk\u001b[39m.\u001b[39;49mdata\u001b[39m.\u001b[39;49mfind(\u001b[39mf\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m{\u001b[39;49;00m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msubdir\u001b[39m}\u001b[39;49;00m\u001b[39m/\u001b[39;49m\u001b[39m{\u001b[39;49;00m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m__name\u001b[39m}\u001b[39;49;00m\u001b[39m\"\u001b[39;49m)\n\u001b[0;32m     <a href='file:///~/AppData/Local/Programs/Python/Python39/lib/site-packages/nltk/corpus/util.py?line=81'>82</a>\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mLookupError\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     <a href='file:///~/AppData/Local/Programs/Python/Python39/lib/site-packages/nltk/corpus/util.py?line=82'>83</a>\u001b[0m         \u001b[39mtry\u001b[39;00m:\n","File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\nltk\\data.py:583\u001b[0m, in \u001b[0;36mfind\u001b[1;34m(resource_name, paths)\u001b[0m\n\u001b[0;32m    <a href='file:///~/AppData/Local/Programs/Python/Python39/lib/site-packages/nltk/data.py?line=580'>581</a>\u001b[0m sep \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m*\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m*\u001b[39m \u001b[39m70\u001b[39m\n\u001b[0;32m    <a href='file:///~/AppData/Local/Programs/Python/Python39/lib/site-packages/nltk/data.py?line=581'>582</a>\u001b[0m resource_not_found \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00msep\u001b[39m}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00mmsg\u001b[39m}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00msep\u001b[39m}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m--> <a href='file:///~/AppData/Local/Programs/Python/Python39/lib/site-packages/nltk/data.py?line=582'>583</a>\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mLookupError\u001b[39;00m(resource_not_found)\n","\u001b[1;31mLookupError\u001b[0m: \n**********************************************************************\n  Resource \u001b[93momw-1.4\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('omw-1.4')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mcorpora/omw-1.4\u001b[0m\n\n  Searched in:\n    - 'C:\\\\Users\\\\BHAVYA SREE/nltk_data'\n    - 'C:\\\\Users\\\\BHAVYA SREE\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python39\\\\nltk_data'\n    - 'C:\\\\Users\\\\BHAVYA SREE\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python39\\\\share\\\\nltk_data'\n    - 'C:\\\\Users\\\\BHAVYA SREE\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python39\\\\lib\\\\nltk_data'\n    - 'C:\\\\Users\\\\BHAVYA SREE\\\\AppData\\\\Roaming\\\\nltk_data'\n    - 'C:\\\\nltk_data'\n    - 'D:\\\\nltk_data'\n    - 'E:\\\\nltk_data'\n**********************************************************************\n"]}],"source":["flag=True\n","print(\"BOT: My name is Stark. Let's have a conversation! Also, if you want to exit any time, just type Bye!\")\n","while(flag==True):\n","    user_response = input()\n","    user_response=user_response.lower()\n","    if(user_response!='bye'):\n","        if(user_response=='thanks' or user_response=='thank you' ):\n","            flag=False\n","            print(\"BOT: You are welcome..\")\n","        else:\n","            if(greet(user_response)!=None):\n","                print(\"BOT: \"+greet(user_response))\n","            else:\n","                sent_tokens.append(user_response)\n","                word_tokens=word_tokens+nltk.word_tokenize(user_response)\n","                final_words=list(set(word_tokens))\n","                print(\"BOT: \",end=\"\")\n","                print(response(user_response))\n","                sent_tokens.remove(user_response)\n","    else:\n","        flag=False\n","        print(\"BOT: Goodbye! Take care <3 \")"]},{"cell_type":"markdown","metadata":{"id":"f5yXpRQMXopU"},"source":["\n","\n","---\n","\n"]}],"metadata":{"colab":{"collapsed_sections":[],"name":"Chatbot_code_in_PYTHON.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.9"}},"nbformat":4,"nbformat_minor":0}
